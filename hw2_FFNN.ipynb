{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kütüphaneleri import ettiğimiz blok\n",
    "Numpy: array işlemleri ve sayısal hesaplamalar için kullanılır.\n",
    "TensorFlow: Derin öğrenme modelleri geliştirmek ve yapay nöronlar oluşturmak için kullanılır.\n",
    "Dense: Yapay sinir ağı oluşturmada kullanılır.\n",
    "Dropout: regularization sınıf için kullanılır.\n",
    "MinMaxScaler: Veriyi 0 , 1 aralığında ölçeklemek veya normalleştirmek için kullanılır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasgele sayılar oluşturuyoruz.\n",
    "Buradaki 42 nin özel bir anlamı yoktur. Popüler olduğu için kullanılır.\n",
    "Bu değerler ağın figure 1 de görünen ilk ağırlıklarını oluşturacaktır. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timesteps = 500\n",
    "time = np.linspace(0, 1, timesteps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setinde kullanmak için zaman vektörü oluşturuyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoC = np.sin(2 * np.pi * time) * 50 + 50 + np.random.normal(0, 2, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setindeki şarj durumunu simule edebilmek için ürettiğimiz fonksiyon. Şarj durumu şarj olurken arada şarjı azaltmaktadır ve gerçekçi veri elde etmek için gürültü ekliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SoH = 100 - 0.05 * time * timesteps + np.random.normal(0, 0.5, timesteps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaman ilerledikçe batarya sağlının o.05 azalacak şekilde bir fonksiyonda azalmasını sağlıyoruz. Gerçeği simule edebilmek için gürültü ekliyoruz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(np.column_stack((SoC, SoH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1)): Veriler 0-1 aralığına ölçeklenecek.\n",
    "\n",
    "np.column_stack((SoC, SoH)): SoC ve SoH tek bir 2 boyutlu diziye (shape: (500, 2)) birleştiriliyor.\n",
    "\n",
    "scaler.fit_transform(...): Veriyi öğren ve dönüştür (her sütunu ayrı ayrı 0-1 aralığına çeker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5  \n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - seq_length):\n",
    "    X.append(data_scaled[i:i + seq_length])  \n",
    "    y.append(data_scaled[i + seq_length])  \n",
    "    \n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimize geçmiş 5 örneği verip 6. örneği tahmin etmeye çalışıyoruz\n",
    "\n",
    "X.append(data_scaled[i:i + seq_length]): i’den i+5’e kadar olan 5 satırlık (SoC, SoH) parçayı X’e ekle.\n",
    "\n",
    "y.append(data_scaled[i + seq_length]): Bir sonraki adımın SoC, SoH değerini y’ye ekle. (Yani X->5 zaman adımı, y->1 zaman adımı)\n",
    "\n",
    "X ve Y değerlerini model girişi için array'e çeviriyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verinin %80'i eğitim %20'si test verisi olarak kullanıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.shape[0]: örnek sayısı, -1 demek geriye kalan boyutu otomatik bul.\n",
    "---------------------------------------------\n",
    "X_Train orjinal biçimi şu şekildedir.\n",
    "(num_samples, seq_length, num_features)\n",
    "\n",
    "num_samples: Kaç tane eğitim örneğiniz (sample) var? (ör. 395)\n",
    "\n",
    "seq_length: Kaç zaman adımı alıyorsunuz? (seq_length = 5)\n",
    "\n",
    "num_features: Her zaman adımında kaç değişken var? (SoC, SoH => 2)\n",
    "\n",
    "Dolayısıyla X_train’in boyutu (num_samples, 5, 2) gibi olabilir.\n",
    "\n",
    "Ancak FFNN için tipik olarak 2 boyutlu girdi beklemektedir \n",
    "------------------------------------------\n",
    "Örnek girdi (num_samples, input_dimension)\n",
    "\n",
    "num_samples: Örnek sayısı (satır sayısı)\n",
    "\n",
    "input_dimension: Her örnekteki özellik (feature) sayısı (sütun sayısı)\n",
    "\n",
    "Elimizde 5 zaman adımı ve 2 değişken olduğu için, bunu “tek bir vektör” (yani 1 boyutlu bir satır) gibi ele almak istiyoruz. Toplam 10 sayı (5 * 2 = 10) olduğuna göre, her örnek 10 boyutlu bir vektör şeklinde FFNN’e girsin.\n",
    "---------------------------------------------\n",
    "X_train.reshape(X_train.shape[0], -1)\n",
    "X_train.shape[0]: kaç örnek (sample) olduğunu belirtir (ör. 395).\n",
    "\n",
    "-1 demek, “geri kalanı otomatik hesapla” anlamına gelir. Python/NumPy, 5*2 = 10 boyutunu bilir, dolayısıyla her örneği (395, 10) boyutuna getirir.\n",
    "\n",
    "Bu sayede X_train (num_samples, 5, 2) şeklinden (num_samples, 10) şekline dönmüş olur. Yani her örnek, 10 sütuna sahip düz (flatten) bir vektöre çevrilir. Bu FFNN’in anlayabileceği formattır, çünkü FFNN “gizli katman” girişlerinde sabit boyutlu bir vektör bekler.\n",
    "\n",
    "\n",
    "![alt text][def]\n",
    "\n",
    "[def]: <../Desktop/AI/Driver Drowsiness Detection 2/image.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) model = Sequential([...])\n",
    "Sequential: Keras API’si içinde katmanları sıralı (düz bir şerit halinde) eklediğimiz basit bir model tanımlama yöntemidir.\n",
    "\n",
    "Katmanlar, girilen sıraya göre veriyi işler. Her katmandan çıkan sonuç, bir sonraki katmana girdi olur.\n",
    "-----------------------------------------------------------\n",
    "2) Dense(64, activation='relu', input_shape=(10,))\n",
    "Dense(64): Bu katmanda 64 nöron (yapay nöron) bulunur.\n",
    "\n",
    "Tam bağlı (fully-connected) bir katmandır; önceki katmanın (ya da giriş katmanının) her bir çıktısı, bu katmandaki her nörona bağlanır.\n",
    "\n",
    "activation='relu': ReLU (Rectified Linear Unit) aktivasyon fonksiyonu kullanılır. ReLU, girdi değeri negatifse 0, pozitifse kendisi olacak şekilde çıktı üretir.\n",
    "\n",
    "Daha derin ağlarda “vanishing gradient” sorununun önüne geçmeye yardımcı olduğu için modern ağlarda sıklıkla kullanılır.\n",
    "\n",
    "input_shape=(10,): Girdi vektörünün boyutunu belirtir.\n",
    "\n",
    "Daha önce veriyi “5 zaman adımı * 2 değişken = 10 özellik” olacak şekilde flatten ettiğimiz için, burada 10 boyutlu bir giriş beklenir.\n",
    "\n",
    "input_shape=(10,) demek, “her bir örnek 10 sayıdan oluşuyor” anlamına gelir. İlk katman, bu 10 sayı üzerine kurulur.\n",
    "----------------------------------------------------------\n",
    "Neden 64 nöron?\n",
    "Deneme-yanılma ve deneysel sonuçlara göre seçilebilecek bir hiperparametredir.\n",
    "\n",
    "Veriye yeteri kadar temsil gücü vermek için 64 genelde “orta ölçekte” bir sayı olabilir. Daha karmaşık veya büyük veri setleri için daha fazla nöron da seçilebilir.\n",
    "---------------------------------------------------------\n",
    "3) Dropout(0.2)\n",
    "Dropout(0.2), bir “düzenlileştirme (regularization)” yöntemidir.\n",
    "\n",
    "Eğitim sırasında, bu katmanın hemen önceki katmandaki nöronların %20’si (rastgele seçilerek) geçici olarak devre dışı bırakılır (silinir).\n",
    "\n",
    "Bu sayede ağ, belirli nöronlara veya bağlantılara aşırı bağımlı kalamaz; overfitting (ezberleme) riski azalır.\n",
    "\n",
    "Tahmin aşamasında (inference) dropout kapatılır, yani tüm nöronlar kullanılır.\n",
    "------------------------------------------------------\n",
    "4) Dense(32, activation='relu')\n",
    "İkinci bir gizli katmandır. 32 nöron içerir, yine ReLU aktivasyon kullanır.\n",
    "\n",
    "Daha derin bir mimari (birden fazla katman) kullanmak, ağın daha karmaşık ilişkileri öğrenebilmesini sağlar.\n",
    "\n",
    "Buradaki nöron sayısı yine bir hiperparametredir; 32, 64, 128 gibi farklı değerler denenip en iyi sonuç veren seçilebilir.\n",
    "------------------------------------------------------\n",
    "5) Dropout(0.2) (Tekrar)\n",
    "Bir önceki katmanda da olduğu gibi, yine %20 oranında nöron devre dışı bırakılır.\n",
    "\n",
    "Modelin derinleşmesiyle birlikte, dropout’un tekrarlanması overfitting’i azaltmada faydalı olabilir.\n",
    "---------------------------------------------------\n",
    "6) Dense(2)\n",
    "Çıkış katmanı: 2 nöron içerir; burada aktivasyon fonksiyonu belirtilmemiş, yani varsayılan olarak “linear” (doğrusal) kullanılır.\n",
    "\n",
    "Neden 2 nöron? Çünkü aynı anda 2 farklı çıktıyı (SoC ve SoH) tahmin etmek istiyoruz.\n",
    "\n",
    "Eğer “SoC ve SoH, 0 ile 1 arasında normalize edilmiş” bir regresyon problemi olarak ele alınacaksa, lineer aktivasyon mantıklıdır. Daha sonra scaler.inverse_transform ile orijinal ölçeğe geri dönüyoruz.\n",
    "-------------------------------------------------\n",
    "\n",
    "Neden Bu Yapı?\n",
    "ReLU: Derin ağlarda iyi çalışan, sade ve hızlı bir aktivasyon fonksiyonu.\n",
    "\n",
    "Dropout: Özellikle kısıtlı veri varsa veya model karmaşıksa overfitting’i düşürmek için sıklıkla kullanılır.\n",
    "\n",
    "2 Gizli Katman: Tek katmanlı ağın yetersiz kalabileceği durumlarda, ek katman ekleyerek öğrenme kapasitesini artırırız.\n",
    "\n",
    "2 Çıkış: Tek seferde, 2 ayrı değeri (SoC ve SoH) tahmin edebilmemizi sağlar. Ağ, bu iki hedefi birlikte öğrenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam algoritması kullanarak optimize eder. loss mse ise mean squared error kullanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL NASIL EĞİTİLİR ?\n",
    "---------------------------------\n",
    "\n",
    "Epoch: Tüm eğitim verilerinin (X_train, y_train setinin) bir kez baştan sona ağ tarafından işlenmesidir.\n",
    "\n",
    "50 epoch demek, verilerinizi 50 kez ardışık şekilde ağdan geçirip, her seferinde ağırlıkları güncelleyeceğiniz anlamına gelir.\n",
    "\n",
    "Epoch sayısı arttıkça, model veriyi daha çok “görür” ve potansiyel olarak daha iyi öğrenir; ancak aşırı yüksek epoch sayısı, “overfitting” riskini de artırabilir.\n",
    "-------------------------------------------------------------\n",
    "batch_size=16\n",
    "\n",
    "Batch (mini-batch) kavramı, verileri toplu gruplar hâlinde işlemek demektir.\n",
    "\n",
    "Bir epoch sırasında, veriler tümüyle bir kerede ağırlık güncellemesi yapmak yerine, batch_size kadar örneği modelden geçirip bir “adım” (iteration) yapar, sonra ağırlıkları günceller. Ardından bir sonraki 16 örnekle devam eder.\n",
    "\n",
    "Neden kullanılır?\n",
    "\n",
    "Tüm veriyi bir defada geçirmek (batch_size = tüm dataset) hafıza (RAM, GPU VRAM) açısından maliyetli olabilir.\n",
    "\n",
    "Küçük batch’ler, daha sık güncelleme yaparak ağı daha hızlı veya daha dinamik eğitir.\n",
    "\n",
    "16 mantıklı bir ara değer: genelde 8, 16, 32, 64 gibi güç-of-2 boyutlar tercih edilir (GPU optimizasyonu vb.).\n",
    "------------------------------------------------------------\n",
    "validation_data=(X_test, y_test)\n",
    "\n",
    "Eğitim sırasında, her epoch bitiminde (veya mini-batch’lerin sonunda) modelin doğruluğunu veya kaybını (loss) test verisi üzerinde ölçer.\n",
    "\n",
    "Neden?\n",
    "\n",
    "    Modelin genelleme performansını görür, overfitting olup olmadığını takip edebilirsiniz (örneğin, eğitim kaybı düşerken validasyon kaybı yükseliyorsa aşırı öğrenme başlamıştır).\n",
    "\n",
    "Bu veri, eğitimde “öğrenilen” veri değildir (genelde train verisinden farklı tutulur). Böylece gerçekte yeni veride modelin nasıl performans göstereceğini yaklaşık tahmin edebilirsiniz.\n",
    "----------------------------------------------------------------\n",
    "verbose=1\n",
    "\n",
    "Eğitim sürecinde, ekrana hangi bilgilerin yazılacağını denetleyen parametredir.\n",
    "\n",
    "verbose=1 → Her epoch sonu ekrana epoch numarası, loss, val_loss gibi özet bilgileri yazdırır.\n",
    "\n",
    "verbose=2 → Yine benzer bilgileri yazar ama satırı kısaltır.\n",
    "\n",
    "verbose=0 → Hiçbir şey yazdırmaz (sessiz mod).\n",
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.predict(X_test)\n",
    "\n",
    "Eğitilmiş model, test veri seti X_test üzerinde tahmin yürütür.\n",
    "\n",
    "Modelin son katmanındaki Dense(2)‘nin çıktısı, 2 boyutludur (SoC ve SoH).\n",
    "\n",
    "Daha önce verilerimiz MinMaxScaler ile 0-1 aralığına (normalleştirilmiş) dönüştürülmüştü; dolayısıyla model de 0-1 aralığında tahmin üretir.\n",
    "\n",
    "Çıktılar, numpy array formatında (satırlar örneklere, sütunlar 2 farklı hedefe karşılık gelecek şekilde) döner.\n",
    "------------------------------------------------------------------\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "\n",
    "Tahmin sonuçlarını (0-1 aralığında) eski ölçeğe dönüştürmek için kullanılır.\n",
    "\n",
    "scaler.inverse_transform(...) Metodu, fit_transform sırasında öğrenilen min-max bilgilerini kullanarak, tahminleri orijinal SoC ve SoH aralığına (örneğin 0-100 veya 70-100 aralığı) geri çevirir.\n",
    "\n",
    "Böylece modelin gerçek hayattaki birimlerle (ör. yüzde % SoC/% SoH) tahmin yapıp yapmadığını görebiliriz.\n",
    "-----------------------------------------------------------------\n",
    "Neden Önemli?\n",
    "\n",
    "Modelin eğitimi boyunca verileri 0-1 aralığına normalleştiririz, bu sayede hesaplamalar (ör. kayıp fonksiyonu, aktivasyon fonksiyonları) genelde daha stabil ve hızlı olur.\n",
    "\n",
    "Fakat çıktıları yorumlarken çoğu zaman ham değerlere (ör. gerçek SoC ve SoH yüzdeleri) ihtiyaç duyarız. inverse_transform bu dönüşümü sağlar.\n",
    "\n",
    "Grafikleri veya son kullanıcıya raporlayacağımız çıktıları, bu geri dönüştürülmüş (rescaled) değerlere bakarak sunarız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_rescaled[:, 0], label=\"Actual SoC\", linestyle=\"dashed\")\n",
    "plt.plot(predictions_rescaled[:, 0], label=\"Predicted SoC\", linestyle=\"solid\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"State of Charge (%)\")\n",
    "plt.title(\"FFNN Prediction of SoC\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual vs Predicted SoC Grafiğini çizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_rescaled[:, 1], label=\"Actual SoH\", linestyle=\"dashed\")\n",
    "plt.plot(predictions_rescaled[:, 1], label=\"Predicted SoH\", linestyle=\"solid\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"State of Health (%)\")\n",
    "plt.title(\"FFNN Prediction of SoH\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual vs Predicted SoH Grafiğini çizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
